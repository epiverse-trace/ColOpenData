---
title: "How to download climate data using ColOpenData"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{How to download climate data using ColOpenData}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

**ColOpenData** can be used to access open climate data from Colombia. This climate data is retrieved from the Institute of Hydrology, Meteorology and Environmental Studies [(IDEAM)](http://www.ideam.gov.co/). The climate module allows the user to consult climate data for any Region of Interest (ROI) inside the country and retrieve the information for each station contained inside.

The available information from IDEAM can be accessed using specific internal tags as follows:

```{r IDEAM table, echo = FALSE}
tags <- c(
  "TSSM_CON", "THSM_CON", "TMN_CON", "TMX_CON", "TSTG_CON", "HR_CAL",
  "HRHG_CON", "TV_CAL", "TPR_CAL", "PTPM_CON", "PTPG_CON", "EVTE_CON",
  "FA_CON", "NB_CON", "RCAM_CON", "BSHG_CON", "VVAG_CON", "DVAG_CON",
  "VVMXAG_CON", "DVMXAG_CON"
)
variable <- c(
  "Dry-bulb Temperature", "Wet-bulb Temperature",
  "Minimum Temperature", "Maximum Temperature",
  "Dry-bulb Temperature (Termograph)", "Relative Humidity",
  "Relative Humidity (Hydrograph)", "Vapour Pressure", "Dew Point",
  "Precipitation (Daily)", "Precipitation (Hourly)", "Evaporation",
  "Atmospheric Phenomenon", "Cloudiness", "Wind Trajectory",
  "Solar Luminosity", "Wind Speed", "Wind Direction",
  "Maximum Wind Speed", "Maximum Wind Direction"
)

IDEAM_tags <- data.frame(
  Tags = tags, Variable = variable,
  stringsAsFactors = FALSE
)
knitr::kable(IDEAM_tags)
```

Each observation is subject to the availability of stations in the ROI and the stations' status (active, maintenance or suspended).

For this example we will retrieve data for the city of Manizales in Colombia. We will download Maximum temperature from 2013 to 2016, to observe the increase in temperature during 2015 and 2016 due to the impact of El Nino (ENSO).

We will start by loading the needed libraries.

```{r library imports, results = "hide", warning = FALSE, message = FALSE}
library(ColOpenData)
library(sf)
library(leaflet)
library(ggplot2)
```

## Retrieving climate data for a Region of Interest (ROI) using stations' data

For this example, we will need to create a spatial polygon around the city of Manizales and use that as our ROI to retrieve the climate data. To create the spatial polygon we need to introduce the coordinates of the geometry. For simplicity, we will build a box by introducing the 4 points which bound the box, and transform the created geometry into an `sf` object (see [**sf**](https://r-spatial.github.io/sf/articles/sf1.html) library for further details). For visualization we will use **leaflet**.

```{r polygon creation}
# Define coordinates (Bounding box around Manizales)
lat <- c(5.166278, 5.166278, 4.982247, 4.982247, 5.166278)
lon <- c(-75.678072, -75.327859, -75.327859, -75.678072, -75.678072)

# Use sf to create a polygon and turn it into a geometry
polygon <- st_polygon(x = list(cbind(lon, lat))) %>% st_sfc()

# Turn geometry into sf object
roi <- st_as_sf(polygon)

# plot polygon for reference
leaflet(roi) %>%
  addProviderTiles("OpenStreetMap") %>%
  addPolygons(
    stroke = TRUE,
    weight = 2,
    color = "#2e6930",
    fillColor = "#2e6930",
    opacity = 0.6
  )
```

With our new ROI, we can make a first exploration to check if there are any stations contained inside of it, using the function `stations_in_roi`

```{r stations in roi, }
stations <- stations_in_roi(roi)
stations
```

We can see that in the region there are 129 stations. Different categories are recorded by different stations, and can be checked at the column [categoria]{.underline}. To understand the category of each station we can use the definition catalog provided by IDEAM [here](http://www.ideam.gov.co/documents/10182/557765/Definiciones+CNE.pdf/25e1cca5-ee47-4eaf-86c0-c4f5192a9937). Stations under the categories *Climática Principal* and *Climática Ordinaria* have records of temperature.

Some stations are suspended, which means they are not taking measurements at the moment. This information is found at the column [estado]{.underline} or, if the observation at [fecha_suspension]{.underline} is different from `NA`, since active stations do not have a suspension date. However, even if a station is suspended, the historical data (up to the suspension date) can be accessed.

To filter the stations that recorded information during the desired period, we can delete the stations with suspension dates before 2013.

```{r}
# Working stations after 2013
w_stations <- stations %>%
  dplyr::filter(as.Date(fecha_suspension) > as.Date("2013-01-01") |
    estado == "Activa")
# Filtering for categories
cw_stations <- w_stations %>% dplyr::filter(categoria %in%
  c("Climática Principal", "Climática Ordinaria"))

# General information of stations
cw_stations
```

From the original 129 stations, 40 were working for some or the whole period of interest and collected information for Dry-bulb temperature. It is important to consider that after data collection, some information might be lost due to quality attributes. 

With the stations, we can access the maximum temperature from 2013 to 2016. To do so, we can use the function `download_climate_stations`. This function has the following parameters:

-   `stations` `data.frame` containing the stations' codes. This `data.frame` must be retrieved from the function `stations_in_roi()`
-   `start_date`: character with the first date to consult in the format `"YYYY-MM-DD"`
-   `end_date`: character with the last date to consult in the format `"YYYY-MM_DD"`. (Last available date is `"2023-05-31"`
-   `tag`: character containing climate tag to consult

```{r download climate stations}
max_temperature_stations <- download_climate_stations(
  stations = w_stations,
  start_date = "2013-01-01",
  end_date = "2016-12-31",
  tag = "TMX_CON"
)
max_temperature_stations
```

The returned tidy `data.frame` includes: Individual and unique station code, longitude, latitude
date, hour, tag requested and value recorded at the specified time. The tidy structure reports a row for each observation, which makes the subset and plot activities easier.

To plot a time series of the stations data we can use **ggplot2** as follows:

```{r plot temperatures stations}
ggplot(data = max_temperature_stations) +
  geom_line(aes(x = date, y = value, group = station), color = "#106ba0") +
  ggtitle("Max Temperature in Manizales by station") +
  xlab("Date") +
  ylab("Temperature [°C]") +
  theme_bw() +
  facet_grid(rows = vars(station))
```
As we can see, only two stations have data for the selected period, and we have missing information in some periods. Additionally, by having the data daily we cannot easily see big changes along time. To aid this issue, we will use an aggregation function. Aggregation functions are available at **ColOpenData** for climate data, we will use `aggregate_climate()`, adding as parameter the desired aggregation.

```{r}
max_temperature_month <- max_temperature_stations %>% aggregate_climate("month")

ggplot(data = max_temperature_month) +
  geom_line(aes(x = date, y = value, group = station), color = "#106ba0") +
  ggtitle("Dry-bulb Temperature") +
  xlab("Date") +
  ylab("Dry-bulb temperature [C]") +
  theme_bw() +
  facet_grid(rows = vars(station))
```

## Retrieving climate data for a Region of Interest (ROI)

To retrieve climate data for any ROI in the country, without manually extracting the stations' data, we can use the function `download_climate_geom`. The function has the following parameters:

-   `geometry`: `sf` geometry containing the geometry for a given ROI. This geometry can be either a `POLYGON` or `MULTIPOLYGON`
-   `start_date`: character with the first date to consult in the format `"YYYY-MM-DD"`
-   `end_date`: character with the last date to consult in the format `"YYYY-MM_DD"`. (Last available date is `"2023-05-31"`)
-   `tag`: character containing climate tag to consult

We will use the same ROI created for the previous example, and add the aggregation for month. We can add the aggregation function to the workflow using the pipe operator `%>%`.

```{r download climate data, results = "hide", warning = FALSE, message = FALSE}
max_temperature_roi <- download_climate_geom(
  geometry = roi,
  start_date = "2013-01-01",
  end_date = "2016-12-31",
  tag = "TMX_CON"
) %>% aggregate_climate("month")
```

```{r plot temperatures roi}
ggplot(data = max_temperature_roi) +
  geom_line(aes(x = date, y = value, group = station), color = "#106ba0") +
  ggtitle("Dry-bulb Temperature") +
  xlab("Date") +
  ylab("Dry-bulb temperature [C]") +
  theme_bw() +
  facet_grid(rows = vars(station))
```

## Retrieving climate data for municipality

To make the download process even easier, and avoid the creation of already known geometries like municipalities or departments, **ColOpenData** offers an extra function to download data using the areas' DIVIPOLA code.

DIVIPOLA codification is standardized for the whole country, and contains department's and municipalities' codes. Departments have two digits for individual identification, while municipalities have three; however, for the usage of this function at the level of municipalities, we need to concatenate both, obtaining a five digit number with department and municipality codes. The codes for each municipality and department can be consulted in the following [table](https://www.datos.gov.co/widgets/gdxc-w37w).

To replicate our previous example we only need the code for Manizales, which is `"17001"`, which means the code for the department Caldas (where Manizales is located) is `"17"` and the code for Manizales inside that department is `"001"`.

The function `download_climate` will require almost the same arguments than `download_climate_geom`, but replace the `sf` object for a character containing the DIVIPOLA code:

-   `code`: character with the DIVIPOLA code for the area
-   `start_date`: character with the first date to consult in the format `"YYYY-MM-DD"`
-   `end_date`: character with the last date to consult in the format `"YYYY-MM_DD"`. (Last available date is `"2023-05-31"`)
-   `tag`: character containing climate tag to consult

```{r download climate mpio, results = "hide", warning = FALSE, message = FALSE}
max_temperature_mpio <- download_climate(
  code = "17001",
  start_date = "2013-01-01",
  end_date = "2016-12-31",
  tag = "TMX_CON"
) %>% aggregate_climate("month")
```

```{r plot temperatures mpios}
ggplot(data = max_temperature_mpio) +
  geom_line(aes(x = date, y = value, group = station), color = "#106ba0") +
  ggtitle("Dry-bulb Temperature") +
  xlab("Date") +
  ylab("Dry-bulb temperature [C]") +
  theme_bw() +
  facet_grid(rows = vars(station))
```

The three methods display the same results, and the increase in maximum monthly temperature can be perceived during 2015 and 2016.

## Disclaimer

Data availability is subdued to station's measurements and quality filters. In most cases this leads to a lower amount of data, considering the extensive amount of climate stations.

Temporal aggregation is only available for some tags and is limited to the ones who have a specific methodology of aggregation reported by IDEAM. The daily, monthly and annual aggregation is available for:
- `TSSM_CON`: Dry-bulb temperature
- `TMX_CON`: Maximum temperature
- `TMN_CON`: Minimum temperature
- `PTPM_CON`: Precipitation
- `BSHG_CON`: Sunshine duration

Temporal and spatial interpolation are not included in this version of **ColOpenData**.
